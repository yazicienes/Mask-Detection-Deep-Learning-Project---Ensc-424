{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "maskDetection.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "XZzZdHRe2qUx",
        "NEt5Q8cQ2l54"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZzZdHRe2qUx"
      },
      "source": [
        "#Serialize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9MvOnEiLGb7"
      },
      "source": [
        "#use this code to serialize images ->generate pickle files\n",
        "#import packages as needed\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "\n",
        "###################preprocessing the data##############\n",
        "\n",
        "#data set directory\n",
        "with_mask_dir = '/content/dataset/with_mask'\n",
        "without_mask_dir = '/content/dataset/without_mask'\n",
        "\n",
        "with_mask_data=[]\n",
        "without_mask_data=[]\n",
        "\n",
        "# load data set and convert each image to an array of numbers\n",
        "for path in os.listdir(with_mask_dir):\n",
        "    full_path = os.path.join(with_mask_dir, path)\n",
        "    if (os.path.isfile(full_path) and ('jpg' in full_path)):\n",
        "      image = cv2.imread(full_path)\n",
        "      #resize all images to the same size\n",
        "      image = cv2.resize(image,(128,128))\n",
        "      #scale down data set to 0-1 range\n",
        "      img = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "      with_mask_data.append([img,0])\n",
        "\n",
        "for path in os.listdir(without_mask_dir):\n",
        "    full_path = os.path.join(without_mask_dir, path)\n",
        "    if (os.path.isfile(full_path) and ('jpg' in full_path)):\n",
        "      image = cv2.imread(full_path)\n",
        "      #resize all images to the same size\n",
        "      image = cv2.resize(image,(128,128))\n",
        "      #scale down data set to 0-1 range\n",
        "      img = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "      without_mask_data.append([img,1])\n",
        "\n",
        "training_data = with_mask_data + without_mask_data;\n",
        "random.shuffle(training_data);\n",
        "x=[];\n",
        "y=[];\n",
        "for img, label in training_data:\n",
        "  x.append(img);\n",
        "  y.append(label)\n",
        "\n",
        "#save the train data, pickles files reusable\n",
        "pickle_out = open(\"images.pickle\", \"wb\");\n",
        "pickle.dump(x, pickle_out)\n",
        "pickle_out.close()\n",
        "pickle_out = open(\"labels.pickle\", \"wb\");\n",
        "pickle.dump(y, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBvKkxzWTyzQ"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4llmAT7q7Ny_"
      },
      "source": [
        "#use this code to train a model\n",
        "#import packages as needed\n",
        "from keras.models import Sequential, model_from_json\n",
        "from keras.layers import *\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "\n",
        "import os\n",
        "import tensorboard\n",
        "import datetime\n",
        "###################preprocessing the data##############\n",
        "\n",
        "#data set directory\n",
        "with_mask_dir = '/content/dataset/with_mask'\n",
        "without_mask_dir = '/content/dataset/without_mask'\n",
        "\n",
        "with_mask_data=[]\n",
        "without_mask_data=[]\n",
        "x=[];\n",
        "y=[];\n",
        "# load data set and convert each image to an array of numbers\n",
        "try:\n",
        "  for path in os.listdir(with_mask_dir):\n",
        "      full_path = os.path.join(with_mask_dir, path)\n",
        "      if (os.path.isfile(full_path) and ('jpg' in full_path)):\n",
        "        image = cv2.imread(full_path)\n",
        "        #resize all images to the same size\n",
        "        image = cv2.resize(image,(128,128))\n",
        "        #scale down data set to 0-1 range\n",
        "        img = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "        with_mask_data.append([img,0])\n",
        "\n",
        "  for path in os.listdir(without_mask_dir):\n",
        "      full_path = os.path.join(without_mask_dir, path)\n",
        "      if (os.path.isfile(full_path) and ('jpg' in full_path)):\n",
        "        image = cv2.imread(full_path)\n",
        "        #resize all images to the same size\n",
        "        image = cv2.resize(image,(128,128))\n",
        "        #scale down data set to 0-1 range\n",
        "        img = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "        without_mask_data.append([img,1])\n",
        "\n",
        "  training_data = with_mask_data + without_mask_data;\n",
        "  random.shuffle(training_data);\n",
        "\n",
        "  for img, label in training_data:\n",
        "    x.append(img);\n",
        "    y.append(label)\n",
        "except:\n",
        "  #load pickle file, use this if you are not using original dataset\n",
        "  pickle_in = open(\"images.pickle\", \"rb\");\n",
        "  x = pickle.load(pickle_in)\n",
        "  pickle_in = open(\"labels.pickle\", \"rb\");\n",
        "  y = pickle.load(pickle_in)\n",
        "####################training the model##########\n",
        "\n",
        "#create a model\n",
        "model = keras.models.Sequential()\n",
        "#add layers\n",
        "#first layer\n",
        "model.add(Conv2D(128, (3,3), activation=\"relu\", input_shape=(128,128,3)))\n",
        "#middle layers\n",
        "model.add(Conv2D(100, (3,3), activation=\"relu\"))\n",
        "# use maxpooling to decrease number of parameters to speed up process\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(256, (3,3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(512, (3,3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(256, (3,3), activation=\"relu\"))\n",
        "model.add(Conv2D(128, (3,3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Dense(64))\n",
        "#last layer\n",
        "model.add(Dense(1,activation=\"sigmoid\"))\n",
        "#print a summary of the model\n",
        "model.summary()\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "#compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "#train the model\n",
        "x = np.array(x);\n",
        "y = np.array(y);\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "model.fit(x, y, batch_size=8, epochs=10, validation_split=0.2, callbacks=[tensorboard_callback])\n",
        "\n",
        "#save the trained model for later use\n",
        "model.save(\"detectmask.model\")\n",
        "#save model weights\n",
        "#model.sample_weights(\"model_weights.h5\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEt5Q8cQ2l54"
      },
      "source": [
        "#TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5T9mEP33c0S8"
      },
      "source": [
        "# use this code to analyze/optimize the model with tensorboard\n",
        "# Load the TensorBoard notebook extension \n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rl4sR9g2RNa"
      },
      "source": [
        "#Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDYXkicx4nzJ"
      },
      "source": [
        "#use this code to predict mask wearing using the trained model\n",
        "import numpy as np\n",
        "import cv2\n",
        "from keras.models import Sequential, model_from_json\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import imutils\n",
        "import dlib\n",
        "import cv2\n",
        "\n",
        "class_labels =[\n",
        "               \"with_mask\",#0\n",
        "               \"without_mask\"#1\n",
        "]\n",
        "\n",
        "#load images to predict\n",
        "full_path = '/content/'\n",
        "list_of_images_to_test = []\n",
        "images = []\n",
        "for path in os.listdir(full_path):\n",
        "  if (('jpeg' in path) or ('jpg' in path)):\n",
        "    image = cv2.imread(path)\n",
        "    image = cv2.resize(image,(128,128))\n",
        "    img = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "    images.append(image)\n",
        "    list_of_images_to_test.append(img)\n",
        "list_of_images_to_test = np.array(list_of_images_to_test)\n",
        "if (len(list_of_images_to_test)==1):\n",
        "  list_of_images_to_test = np.expand_dims(img, axis=0)\n",
        "# load the trained model\n",
        "model = tf.keras.models.load_model(\"detectmask.model\")\n",
        "results = model.predict(list_of_images_to_test)\n",
        "i = 0\n",
        "for res in results:\n",
        "  print (res)\n",
        "  index = ((res > 0.5)+0).ravel() #prediction is in class_labels[index[0]]\n",
        "  #use haarcascade to detect face\n",
        "  face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "  img2 = cv2.normalize(images[i], None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
        "  img2 = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
        "  faces = face_cascade.detectMultiScale(images[i]) #expects 1 channel image\n",
        "  for (x,y,w,h) in faces:\n",
        "    if index == 0:#with mask, green rectangle\n",
        "      cv2.rectangle(images[i], (x,y), (x+w,y+h), (0,128,0), 2) #rectangle color and line width\n",
        "      cv2.putText(images[i], 'with mask', (x, y-5), cv2.FONT_HERSHEY_PLAIN, 0.5, (0,128,0), 1)\n",
        "    else:#without mask, red rectange\n",
        "      cv2.rectangle(images[i], (x,y), (x+w,y+h), (0,0,255), 2) #rectangle color and line width\n",
        "      cv2.putText(images[i], 'without mask', (x, y-5), cv2.FONT_HERSHEY_PLAIN, 0.5, (0,0,255), 1)\n",
        "\n",
        "  print(class_labels[index[0]])\n",
        "  #plt.imshow(image)\n",
        "  image = cv2.resize(images[i],(256,256))\n",
        "  cv2_imshow(np.array(images[i], dtype = np.uint8 ))\n",
        "  i += 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}